{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from ai_cdss.constants import BY_ID, BY_PPS\n",
    "\n",
    "def check_session(session: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check for data discrepancies in session DataFrame, export findings to ~/.ai_cdss/logs/,\n",
    "    log summary, and return cleaned DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session : pd.DataFrame\n",
    "        Session DataFrame to check and clean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned session DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 0: Setup paths\n",
    "    log_dir = os.path.expanduser(\"~/.ai_cdss/logs/\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    log_file = os.path.join(log_dir, \"data_check.log\")\n",
    "\n",
    "    # Setup logging (re-setup per function call to ensure correct log file)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Step 1: Patient registered but no data yet (no prescription)\n",
    "    print(\"Patient registered but no data yet.\")\n",
    "    patients_no_data = session[session[\"PRESCRIPTION_ID\"].isna()]\n",
    "    if not patients_no_data.empty:\n",
    "        export_file = os.path.join(log_dir, f\"patients_no_data_{timestamp}.csv\")\n",
    "        patients_no_data[[\"PATIENT_ID\", \"PRESCRIPTION_ID\", \"SESSION_ID\"]].to_csv(export_file, index=False)\n",
    "        logger.warning(f\"{len(patients_no_data)} patients found without prescription. Check exported file: {export_file}\")\n",
    "    else:\n",
    "        logger.info(\"No patients without prescription found.\")\n",
    "\n",
    "    # Drop these rows\n",
    "    session = session.drop(patients_no_data.index)\n",
    "\n",
    "    # Step 2: Sessions in session table but not in recording table (no adherence)\n",
    "    print(\"Sessions in session table but not in recording table\")\n",
    "    patient_session_discrepancy = session[session[\"ADHERENCE\"].isna()]\n",
    "    if not patient_session_discrepancy.empty:\n",
    "        export_file = os.path.join(log_dir, f\"patient_session_discrepancy_{timestamp}.csv\")\n",
    "        patient_session_discrepancy[[\"PATIENT_ID\", \"PRESCRIPTION_ID\", \"SESSION_ID\"]].to_csv(export_file, index=False)\n",
    "        logger.warning(f\"{len(patient_session_discrepancy)} sessions found without adherence. Check exported file: {export_file}\")\n",
    "    else:\n",
    "        logger.info(\"No sessions without adherence found.\")\n",
    "\n",
    "    # Drop these rows\n",
    "    session = session.drop(patient_session_discrepancy.index)\n",
    "\n",
    "    # Final info\n",
    "    logger.info(f\"Session data cleaned. Final shape: {session.shape}\")\n",
    "\n",
    "    return session\n",
    "\n",
    "def safe_merge(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    on,\n",
    "    how: str = \"left\",\n",
    "    export_dir: str = \"~/.ai_cdss/logs/\",\n",
    "    left_name: str = \"left\",\n",
    "    right_name: str = \"right\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform a safe merge and independently report unmatched rows from left and right DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    left : pd.DataFrame\n",
    "        Left DataFrame.\n",
    "    right : pd.DataFrame\n",
    "        Right DataFrame.\n",
    "    on : str or list\n",
    "        Column(s) to join on.\n",
    "    how : str, optional\n",
    "        Type of merge to be performed. Default is \"left\".\n",
    "    export_dir : str, optional\n",
    "        Directory to export discrepancy reports and logs.\n",
    "    left_name : str, optional\n",
    "        Friendly name for the left DataFrame, for logging.\n",
    "    right_name : str, optional\n",
    "        Friendly name for the right DataFrame, for logging.\n",
    "    drop_inconsistencies : bool, optional\n",
    "        If True, drop inconsistent rows (left-only). Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Merged DataFrame.\n",
    "    \"\"\"\n",
    "    # Prepare export directory\n",
    "    export_dir = os.path.expanduser(export_dir)\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_file = os.path.join(export_dir, \"data_check.log\")\n",
    "\n",
    "    # Setup logger â€” clean, no extra clutter\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Step 1: Outer merge for discrepancy check\n",
    "    discrepancy_check = left.merge(right, on=on, how=\"outer\", indicator=True)\n",
    "\n",
    "    left_only = discrepancy_check[discrepancy_check[\"_merge\"] == \"left_only\"]\n",
    "    right_only = discrepancy_check[discrepancy_check[\"_merge\"] == \"right_only\"]\n",
    "\n",
    "    # Step 2: Export and log discrepancies if found\n",
    "\n",
    "    if not left_only.empty:\n",
    "        export_file = os.path.join(export_dir, f\"{left_name}_only_{timestamp}.csv\")\n",
    "        try:\n",
    "            left_only[BY_ID + [\"SESSION_DURATION\", \"SCORE\", \"DM_VALUE\", \"PE_VALUE\"]].to_csv(export_file, index=False)\n",
    "        except KeyError as e:\n",
    "            left_only.to_csv(export_file, index=False)\n",
    "            \n",
    "        logger.warning(\n",
    "            f\"{len(left_only)} rows found only in '{left_name}' DataFrame \"\n",
    "            f\"(see export: {export_file})\"\n",
    "        )\n",
    "\n",
    "    if not right_only.empty:\n",
    "        export_file = os.path.join(export_dir, f\"{right_name}_only_{timestamp}.csv\")\n",
    "        try:\n",
    "            right_only[BY_PPS + [\"SESSION_DURATION\", \"SCORE\", \"DM_VALUE\", \"PE_VALUE\"]].to_csv(export_file, index=False)\n",
    "        except KeyError as e:\n",
    "            right_only.to_csv(export_file, index=False)\n",
    "        logger.warning(\n",
    "            f\"{len(right_only)} rows from '{right_name}' DataFrame did not match '{left_name}' DataFrame \"\n",
    "            f\"(see export: {export_file})\"\n",
    "        )\n",
    "\n",
    "    # Step 3: Actual requested merge\n",
    "    merged = left.merge(right, on=on, how=how)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ai_cdss.data_loader:PPF data loaded successfully.\n",
      "INFO:ai_cdss.data_loader:Protocol similarity data loaded successfully.\n",
      "INFO:ai_cdss.data_loader:Protocol initialization data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from joblib import Memory\n",
    "memory = Memory(location='cache_dir', verbose=0)\n",
    "\n",
    "@memory.cache\n",
    "def load_session_cached(patient_list):\n",
    "    return check_session(loader.load_session_data(patient_list=patient_list))\n",
    "\n",
    "@memory.cache\n",
    "def load_timeseries_cached(patient_list):\n",
    "    return loader.load_timeseries_data(patient_list=patient_list)\n",
    "\n",
    "SAVE_DATA = True\n",
    "EXPAND = False\n",
    "\n",
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "from ai_cdss.data_loader import DataLoader\n",
    "from ai_cdss.data_processor import DataProcessor\n",
    "from ai_cdss.processing import expand_session_batch\n",
    "from ai_cdss.constants import *\n",
    "\n",
    "# NEST DATA\n",
    "nest_patient = [\n",
    "    775,  787,  788, 1123, 1169, 1170, 1171, 1172, 1173, 1983, 2110, 2195,\n",
    "    2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 3081, 3229, 3318, 3432\n",
    "]\n",
    "\n",
    "rgs_mode = \"app\"\n",
    "scoring_weights = [1,1,1]\n",
    "ewma_alpha = 0.2\n",
    "\n",
    "n = 12\n",
    "days = 7\n",
    "protocols_per_day = 5\n",
    "\n",
    "loader = DataLoader(rgs_mode=rgs_mode)\n",
    "processor = DataProcessor(weights=scoring_weights, alpha=ewma_alpha)\n",
    "\n",
    "# Load Data\n",
    "session = load_session_cached(nest_patient)\n",
    "timeseries = load_timeseries_cached(nest_patient)\n",
    "ppf = loader.load_ppf_data(patient_list=nest_patient)\n",
    "\n",
    "# ppf = loader.load_ppf_data(patient_list=nest_patient)\n",
    "protocol_similarity = loader.load_protocol_similarity()\n",
    "protocol_metrics = loader.load_protocol_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:1051 rows found only in 'session' DataFrame (see export: /home/dav/.ai_cdss/logs/session_only_20250408_131601.csv)\n",
      "WARNING:__main__:58 rows from 'ts' DataFrame did not match 'session' DataFrame (see export: /home/dav/.ai_cdss/logs/ts_only_20250408_131601.csv)\n",
      "WARNING:__main__:643 rows from 'ppf' DataFrame did not match 'session' DataFrame (see export: /home/dav/.ai_cdss/logs/ppf_only_20250408_131601.csv)\n"
     ]
    }
   ],
   "source": [
    "# # Process Data\n",
    "# session = session.dropna(subset=[\"ADHERENCE\"])\n",
    "# ts = processor.aggregate_dms_by_time(timeseries)\n",
    "# ts = ts.sort_values(by=BY_PPST)\n",
    "# # Merge\n",
    "# data = safe_merge(session, ts, on=BY_PPS, how=\"inner\", left_name=\"session\", right_name=\"ts\")\n",
    "# score_data = safe_merge(data, ppf, on=BY_PP, how=\"left\", left_name=\"session\", right_name=\"ppf\")\n",
    "# score_data.sort_values(by=BY_PPST, inplace=True)\n",
    "\n",
    "# score_data.to_parquet(\"data/nest_data.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-cdss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
